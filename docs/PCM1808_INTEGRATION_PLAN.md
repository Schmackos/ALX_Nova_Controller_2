# Plan: PCM1808 Audio ADC Integration (Major Feature)

## Overview
Replace the 12-bit `analogRead()` voltage detection with a PCM1808 24-bit stereo I2S ADC. Phase 1 replaces the core detection with native dBFS thresholds (no backward-compatible voltage mapping). Phases 2-4 add level metering, waveform visualization, and FFT/spectrum analysis.

**Decisions made:**
- Native dBFS threshold from the start (not voltage-equivalent mapping)
- Selectable sample rate: 16,000 / 44,100 / 48,000 Hz (default 48kHz for video/film audio)
- JSON uint8 array for WebSocket waveform data
- Scope: Phases 1-4 (core + metering + waveform + FFT)
- Phases 5-7 (noise gate, GUI screen, MQTT entities) deferred for later

---

## What the PCM1808 Brings Over analogRead()

| Capability | Old (ESP32 ADC) | New (PCM1808) |
|-----------|-----------------|---------------|
| Resolution | 12-bit (4096 levels) | 24-bit (16.7M levels) |
| Dynamic Range | ~72 dB | ~99 dB SNR |
| Channels | 1 (mono) | 2 (stereo L+R) |
| Sample Rate | ~20 Hz effective (50ms poll) | 16k / 44.1k / 48k Hz selectable |
| DC Offset | Drifts with temp/power | Built-in 1.8Hz HPF removes DC |
| CPU Load | Blocks ~100us per read | Zero (DMA background transfer) |
| Noise Floor | ~-40 dBFS | ~-99 dBFS |
| Audio Analysis | None (just voltage level) | RMS, Peak, FFT, Spectrum, Frequency |

---

## Hardware Wiring

```
PCM1808 Module         ESP32-S3
──────────────         ────────
+5V              ->    5V (USB VBUS)
GND              ->    GND
BCK              ->    GPIO 16  (I2S Bit Clock)
OUT (DOUT)       ->    GPIO 17  (I2S Data In)
LRC              ->    GPIO 18  (I2S Word Select)
SCK              <-    GPIO 3   (MCLK, generated by ESP32-S3 APLL)
FMT              ->    GND      (I2S standard format)
MD1              ->    GND      (Slave mode)
MD0              ->    GND      (Slave mode, 256fs)
LIN              <-    Left audio input (wire/RCA)
RIN              <-    Right audio input (wire/RCA)
3.3V                   (module-generated, do NOT connect to ESP32 3.3V)
```

**Pin rationale:** GPIOs 3, 16-18 are all completely free (current usage: TFT SPI on 10-14, encoder on 5-7, LED/amp/button on 2/4/15, buzzer on 8, backlight on 21).

---

## Phase 1: Core I2S + dBFS-based Detection

**Goal:** Replace `analogRead()` with I2S audio RMS. Switch threshold system from voltage (0.1-3.3V) to dBFS (-96 to 0). Update all interfaces (WebSocket, MQTT, API, GUI, settings) to use native audio units.

### How It Works
- I2S captures 44.1kHz 24-bit stereo audio via DMA (zero CPU overhead)
- A FreeRTOS task on Core 0 reads DMA buffers every ~6ms and computes RMS
- RMS is converted to dBFS: `20 * log10(rms)` where 0 dBFS = digital full scale
- Signal detection: `signalDetected = (audiodBFS >= audioThreshold_dBFS)`
- The existing FSM, timer, and relay logic work unchanged — only the detection input changes

### Threshold Migration (Voltage -> dBFS)
- Old: `voltageThreshold` float, range 0.1-3.3V, default 0.1V, stored in `/smartsensing.txt` line 3
- New: `audioThreshold` float, range -96 to 0 dBFS, default **-40 dBFS**
- **-40 dBFS** is a reasonable default for "audio signal present" (equivalent to ~1% of full scale)
- Settings migration: on load, if stored value is in 0.1-3.3 range, convert: `dBFS = 20 * log10(voltage / 3.3)` — this auto-migrates existing settings

### New Files

| File | Purpose | ~Lines |
|------|---------|--------|
| `src/i2s_audio.h` | I2S pin defs, AudioAnalysis struct, public API | ~50 |
| `src/i2s_audio.cpp` | I2S driver init, DMA config, audio capture task, RMS calc | ~170 |
| `test/test_i2s_audio/test_audio_rms.cpp` | RMS calc, dBFS conversion, threshold migration tests | ~100 |

### Modified Files

| File | Change |
|------|--------|
| `src/app_state.h` | Rename `lastVoltageReading` -> `audioLevel_dBFS`, `voltageThreshold` -> `audioThreshold_dBFS`, add `audioRmsLeft/Right/Combined`, `audioPeakCombined`, `audioSampleRate` (uint32_t, default 48000), update dirty flags, update legacy macros |
| `src/smart_sensing.cpp` | Replace `detectVoltage()` internals: call `i2s_audio_get_analysis()` instead of `analogRead()`. Update `sendSmartSensingStateInternal()` JSON to use dBFS fields. Update `handleSmartSensingGet/Update()` API to accept dBFS threshold. Update settings load/save with migration logic. |
| `src/main.cpp` | Add `#include "i2s_audio.h"`, replace `pinMode(VOLTAGE_SENSE_PIN, INPUT)` with `i2s_audio_init()` |
| `src/config.h` | Add `TASK_STACK_SIZE_AUDIO`, `TASK_PRIORITY_AUDIO`, `DEFAULT_AUDIO_SAMPLE_RATE = 48000`. Change `DEFAULT_VOLTAGE_THRESHOLD` to `DEFAULT_AUDIO_THRESHOLD = -40.0f` (dBFS). Remove/deprecate `VOLTAGE_SENSE_PIN`. |
| `src/mqtt_handler.cpp` | Update `publishMqttSmartSensingState()`: publish dBFS instead of voltage. Update MQTT subscribe callback for threshold. Update HA discovery entity for threshold (number entity: -96 to 0 dBFS). |
| `src/gui/screens/scr_home.cpp` | Change signal display from `"%.2fV Detected"` to `"%+.0f dBFS Detected"` |
| `src/gui/screens/scr_control.cpp` | Change voltage threshold editor: range -96 to 0, step 1, format `"%+.0f dBFS"` |
| `src/gui/screens/scr_desktop.cpp` | Update Control card summary: show dBFS instead of voltage |
| `src/web_pages.cpp` | Update Smart Sensing section: show dBFS level/threshold, update slider/input range, update JS WebSocket handler |
| `platformio.ini` | Remove `VOLTAGE_SENSE_PIN=1`, add I2S pin defines |
| `test/test_smart_sensing/` | Update mock detectVoltage() to use dBFS, verify threshold logic |

### I2S Configuration
- **Peripheral:** I2S_NUM_1 (avoids any PSRAM conflict)
- **Mode:** Master RX (ESP32 generates all clocks, PCM1808 in slave mode)
- **Sample rate:** Selectable — default 48,000 Hz (video/film native rate)
  - 16,000 Hz: MCLK = 4.096 MHz — minimal bandwidth, sufficient for signal detection
  - 44,100 Hz: MCLK = 11.29 MHz — CD/music native rate
  - 48,000 Hz: MCLK = 12.288 MHz — video/film native rate, cleanest clock division
- **Bit depth:** 32-bit frames (PCM1808 sends 24-bit left-justified)
- **DMA:** 4 buffers x 256 samples = 8KB total
- **APLL:** Enabled for accurate audio clock generation
- **Runtime switching:** `i2s_audio_set_sample_rate(uint32_t rate)` — stops I2S, reconfigures, restarts (~100ms gap). Recalculates all derived constants (MCLK, FFT bin width, waveform downsampling ratio).

### Sample Rate Setting
- **Stored in:** `/smartsensing.txt` line 4 (new line, backward-compat: missing = default 48000)
- **AppState field:** `uint32_t audioSampleRate` (16000, 44100, or 48000)
- **Exposed via:** REST API (`GET/POST /api/smartsensing`), WebSocket (`smartSensing` message), MQTT, GUI Settings/Control screen
- **FFT resolution impact:**

| Sample Rate | MCLK | Nyquist | FFT Resolution (1024-pt) | DMA Buffer Time |
|-------------|------|---------|--------------------------|-----------------|
| 16,000 Hz | 4.10 MHz | 8,000 Hz | 15.6 Hz/bin | 16.0 ms |
| 44,100 Hz | 11.29 MHz | 22,050 Hz | 43.1 Hz/bin | 5.8 ms |
| 48,000 Hz | 12.29 MHz | 24,000 Hz | 46.9 Hz/bin | 5.3 ms |

### Audio Capture Task
- **Core:** 0 (time-critical, same as existing sensing task)
- **Priority:** 3 (highest app task — must not drop I2S samples)
- **Stack:** 4096 bytes
- **Loop:** Read 256 stereo samples (~5.8ms), compute RMS + dBFS, update shared state
- **Thread safety:** Double-buffer with atomic swap pointer, or portENTER_CRITICAL for AudioAnalysis struct copy

### AudioAnalysis Struct (shared between I2S task and consumers)
```cpp
struct AudioAnalysis {
    float rmsLeft;         // 0.0-1.0 (linear)
    float rmsRight;        // 0.0-1.0 (linear)
    float rmsCombined;     // 0.0-1.0 (linear)
    float peakLeft;        // 0.0-1.0 (with decay)
    float peakRight;       // 0.0-1.0 (with decay)
    float peakCombined;    // 0.0-1.0 (with decay)
    float dBFS;            // -96 to 0 (combined level)
    bool  signalDetected;  // dBFS >= threshold
    unsigned long timestamp;
};
```

### WebSocket Message Changes
```json
{
  "type": "smartSensing",
  "mode": "smart_auto",
  "timerDuration": 15,
  "timerRemaining": 120,
  "timerActive": true,
  "amplifierState": true,
  "audioLevel": -18.2,
  "audioThreshold": -40.0,
  "signalDetected": true,
  "audioRmsL": 0.12,
  "audioRmsR": 0.10,
  "audioPeak": 0.45
}
```
Replaces old `voltageReading`, `voltageThreshold`, `voltageDetected` fields.

### MQTT Topic Changes
```
ALX/{serial}/smartsensing/audio_level     # dBFS float (was: voltage)
ALX/{serial}/smartsensing/audio_threshold # dBFS float (was: voltage_threshold)
ALX/{serial}/smartsensing/signal_detected # ON/OFF (was: voltage_detected)
ALX/{serial}/smartsensing/amplifier       # ON/OFF (unchanged)
ALX/{serial}/smartsensing/timer_*         # (unchanged)
ALX/{serial}/smartsensing/mode            # (unchanged)
```

### REST API Changes
- `GET /api/smartsensing`: Returns `audioLevel` (dBFS), `audioThreshold` (dBFS), `signalDetected` (bool) instead of `voltageReading`, `voltageThreshold`, `voltageDetected`
- `POST /api/smartsensing`: Accepts `audioThreshold` (float, -96 to 0) instead of `voltageThreshold`

### Settings Persistence Migration
`/smartsensing.txt` line 3:
- Old format: float 0.1-3.3 (voltage)
- New format: float -96 to 0 (dBFS)
- **Auto-detect on load:** if value > 0, it's old voltage format → convert: `dBFS = 20 * log10(value / 3.3)`. If value <= 0, it's already dBFS.

### Unit Tests — `test/test_i2s_audio/test_audio_rms.cpp` (NEW)
Follows existing test pattern: local mock state, no real I2S hardware.

| # | Test Name | What It Verifies |
|---|-----------|-----------------|
| 1 | `test_rms_silence` | All-zero sample buffer → RMS = 0.0, dBFS ≈ -96 |
| 2 | `test_rms_full_scale_sine` | Full-scale sine wave samples → RMS ≈ 0.707, dBFS ≈ -3.0 |
| 3 | `test_rms_half_scale` | Half-amplitude samples → RMS ≈ 0.354, dBFS ≈ -9.0 |
| 4 | `test_rms_stereo_split` | Left-only signal → rmsLeft > 0, rmsRight ≈ 0 |
| 5 | `test_dbfs_conversion` | Known RMS values map to correct dBFS: 1.0→0, 0.5→-6, 0.1→-20, 0.01→-40 |
| 6 | `test_signal_detection_above_threshold` | dBFS = -30, threshold = -40 → signalDetected = true |
| 7 | `test_signal_detection_below_threshold` | dBFS = -50, threshold = -40 → signalDetected = false |
| 8 | `test_signal_detection_at_threshold` | dBFS = -40, threshold = -40 → signalDetected = true (≥) |
| 9 | `test_threshold_migration_old_voltage` | Value 0.1 (>0) → converts to dBFS ≈ -30.4 |
| 10 | `test_threshold_migration_already_dbfs` | Value -40 (≤0) → kept as-is |
| 11 | `test_threshold_migration_edge_cases` | Value 3.3 → 0 dBFS, value 0.01 → ~-50 dBFS |
| 12 | `test_sample_rate_validation` | Only 16000, 44100, 48000 accepted; others rejected |
| 13 | `test_24bit_sample_parsing` | Left-justified 32-bit I2S frame → correct 24-bit signed extraction |
| 14 | `test_peak_detection` | Peak tracks maximum, decays over time |

### Updates to `test/test_smart_sensing/test_smart_sensing_logic.cpp`
The existing test file uses `TestState::voltageThreshold` and `detectVoltage()` with `ArduinoMock::mockAnalogValue`. These need updating:

| # | Change | Description |
|---|--------|-------------|
| 1 | Rename `voltageThreshold` → `audioThreshold_dBFS` | In TestState namespace |
| 2 | Replace `detectVoltage()` mock | Use dBFS comparison instead of analogRead voltage |
| 3 | Update `test_voltage_threshold_detection` | Test dBFS threshold instead of voltage |
| 4 | Add `test_threshold_dbfs_range_validation` | Verify -96 to 0 range enforcement |
| 5 | Existing FSM tests | Unchanged — they test ALWAYS_ON/OFF/SMART_AUTO logic independent of detection method |

### Risks & Mitigations
1. **MCLK accuracy** — APLL should handle 11.29MHz; fallback: try 48kHz (MCLK=12.288MHz)
2. **I2S data format mismatch** — PCM1808 default matches `I2S_COMM_FORMAT_STAND_I2S`; fallback: toggle FMT pin or try `I2S_COMM_FORMAT_STAND_MSB`
3. **Race condition** — Audio task (Core 0) writes, main loop (Core 1) reads; use double-buffer or critical section
4. **Breaking change for existing users** — Threshold units change from V to dBFS. Auto-migration handles `/smartsensing.txt`. MQTT subscribers will see different topic names/values. Web UI updates in-place.

---

## Phase 2: Audio Level Metering (Web UI)

**Goal:** Add professional-looking level meters (L/R bars, dBFS readout, peak hold) to the web UI Control tab.

### Web UI Additions (in Control tab, `web_pages.cpp`)
New "Audio Signal" card containing:
- **Stereo level bars:** Two horizontal bars (L/R) with gradient fill (green → yellow → orange → red)
- **Peak hold markers:** Thin line at peak position, decays over 2 seconds
- **dBFS readout:** Numeric display "-18.2 dBFS"
- **Signal indicator:** Green dot when signal detected, gray when not

### VU-style Metering (in `i2s_audio.cpp`)
- Attack: 300ms, Decay: 650ms — industry-standard VU ballistics
- Peak hold: separate from VU, instant attack, 2s hold + 300ms decay
- Computed in the audio capture task alongside RMS

### WebSocket Data
Extend the existing `smartSensing` message (already includes `audioRmsL/R`, `audioPeak` from Phase 1).
No new message type needed — reuse the 1s broadcast rate.

### Files Modified
| File | Change |
|------|--------|
| `src/i2s_audio.cpp` | Add VU attack/decay and peak hold computation |
| `src/web_pages.cpp` | Add Audio Signal card with CSS level bars + JS rendering |

### Unit Tests — add to `test/test_i2s_audio/test_audio_rms.cpp`

| # | Test Name | What It Verifies |
|---|-----------|-----------------|
| 15 | `test_vu_attack_ramp` | VU level ramps up with 300ms time constant when signal increases |
| 16 | `test_vu_decay_ramp` | VU level decays with 650ms time constant when signal drops |
| 17 | `test_peak_hold_instant_attack` | Peak jumps immediately to new maximum |
| 18 | `test_peak_hold_2s_duration` | Peak holds for 2 seconds before decaying |
| 19 | `test_peak_decay_after_hold` | Peak decays smoothly after hold period expires |

---

## Phase 3: Waveform Visualization (Web Frontend)

**Goal:** Real-time oscilloscope-style waveform display in the web UI.

### Data Strategy
- **Downsampled 256-point snapshots at 10Hz** (~5 KB/s bandwidth)
- Each point = peak-hold over ~17 source samples (4410 samples / 256 bins per 100ms)
- Quantized to uint8 (0-255) for compact JSON
- **Client-side subscription:** Only sent when Control tab is active

### WebSocket Message
```json
{
  "type": "audioWaveform",
  "w": [128, 140, 155, 130, 110, ...],
  "rmsL": 0.12,
  "rmsR": 0.10,
  "peak": 0.45,
  "dBFS": -18.2
}
```

### Waveform Buffer (in `i2s_audio.cpp`)
```cpp
#define WAVEFORM_BUFFER_SIZE 256
static uint8_t waveformBuffer[WAVEFORM_BUFFER_SIZE];
static volatile bool waveformReady = false;
```
Audio task fills this every 100ms. Main loop copies and sends when ready + client subscribed.

### Canvas Rendering (in `web_pages.cpp`)
Follows existing `drawCpuGraph()` pattern:
- Dark background (#1A1A1A), orange waveform line (#FF9800)
- Center line at 128 (zero crossing), amplitude fills vertically
- 120px canvas height in an "Audio Waveform" card
- devicePixelRatio-aware rendering

### Subscription Protocol
- Browser sends `{"type":"subscribeWaveform","enabled":true}` when entering Control tab
- ESP32 tracks per-client subscription flags
- Only sends `audioWaveform` messages to subscribed clients (not broadcast)

### Files Modified/Added
| File | Change |
|------|--------|
| `src/i2s_audio.h/.cpp` | Add waveform downsampling buffer + 100ms snapshot generation |
| `src/websocket_handler.cpp` | Add subscription tracking + selective waveform send |
| `src/web_pages.cpp` | Add waveform canvas, drawAudioWaveform() JS function, tab switch subscription |

### Unit Tests — add to `test/test_i2s_audio/test_audio_rms.cpp`

| # | Test Name | What It Verifies |
|---|-----------|-----------------|
| 20 | `test_waveform_downsample_silence` | Zero-input buffer → all waveform points = 128 (center) |
| 21 | `test_waveform_downsample_full_scale` | Max-amplitude samples → waveform points at 0 and 255 extremes |
| 22 | `test_waveform_buffer_size` | Output is exactly 256 uint8 values |
| 23 | `test_waveform_peak_hold_per_bin` | Each bin captures the peak (not average) of its source samples |
| 24 | `test_waveform_quantization` | Float -1.0→0, 0.0→128, +1.0→255 mapping is correct |

### Unit Tests — `test/test_websocket/` (extend existing)

| # | Test Name | What It Verifies |
|---|-----------|-----------------|
| 25 | `test_waveform_subscription_default_off` | New clients don't receive waveform data by default |
| 26 | `test_waveform_subscription_on` | Client that sends subscribe message gets waveform data |
| 27 | `test_waveform_subscription_off` | Client that unsubscribes stops receiving waveform data |

---

## Phase 4: Frequency Detection & Spectrum (FFT)

**Goal:** Detect dominant audio frequency (Hz) and provide 16-band spectrum data.

### Library
- `kosme/arduinoFFT@^2.0` — add to `platformio.ini` lib_deps
- Pure C++, no hardware dependency, well-tested
- Alternative: `espressif/esp-dsp` (hardware-accelerated, overkill)

### FFT Configuration
- **1024-point FFT** — resolution depends on sample rate:
  - 16kHz: **15.6 Hz/bin**, 512 bins up to 8kHz Nyquist
  - 44.1kHz: **43.1 Hz/bin**, 512 bins up to 22kHz Nyquist
  - 48kHz: **46.9 Hz/bin**, 512 bins up to 24kHz Nyquist
- ~0.5ms compute time on ESP32-S3 at 240MHz
- Computed every 100ms (10Hz) — same rate as waveform snapshots
- Hamming window applied before FFT
- **Band boundaries are fixed Hz ranges** — the number of FFT bins per band varies with sample rate, handled in the bin-to-band aggregation function

### Outputs
- **Dominant frequency:** `float dominantFreq` in Hz (via `FFT.majorPeak()`)
- **16-band spectrum:** Aggregate FFT bins into musically-spaced bands:
  ```
  Band  0:    20- 60 Hz (Sub-bass)
  Band  1:    60-120 Hz (Bass)
  Band  2:   120-250 Hz (Low-mid)
  Band  3:   250-500 Hz (Mid)
  Band  4:   500-  1k Hz (Upper-mid)
  Band  5:     1k-  2k Hz (Presence)
  Band  6:     2k-  4k Hz (Brilliance)
  Band  7:     4k-  8k Hz (High)
  Band  8:     8k- 12k Hz (Air)
  Band  9:    12k- 16k Hz (Ultra-high)
  Band 10:    16k- 20k Hz (Near-ultrasonic)
  ```
  (11 meaningful bands; can pad to 16 for visual symmetry or add sub-divisions)

### New AppState Fields
```cpp
float audioDominantFreq;       // Hz
float audioSpectrumBands[16];  // 0.0-1.0 per band
```

### WebSocket Message
```json
{
  "type": "audioSpectrum",
  "freq": 440.0,
  "bands": [0.1, 0.3, 0.6, 0.9, 0.7, 0.5, 0.3, 0.2, 0.1, 0.05, 0.02, 0, 0, 0, 0, 0]
}
```
Sent at 10Hz, only to subscribed clients. ~200 bytes per message.

### Web UI: Spectrum Analyzer
Canvas rendering of 16 vertical bars:
- Orange-to-red gradient based on intensity
- Band labels at bottom (optional)
- Frequency readout: "Dominant: 440 Hz"
- 80px canvas height in a "Spectrum" card below the waveform card

### FFT Buffer Management
```cpp
static double vReal[1024];  // ~8 KB
static double vImag[1024];  // ~8 KB
```
Total: 16 KB RAM for FFT. Within budget (221 KB free).

### Files Modified/Added
| File | Change |
|------|--------|
| `src/i2s_audio.h/.cpp` | Add FFT computation, spectrum band aggregation, dominant freq extraction |
| `src/app_state.h` | Add `audioDominantFreq`, `audioSpectrumBands[16]` |
| `src/websocket_handler.cpp` | Add `audioSpectrum` message type (subscription-based) |
| `src/web_pages.cpp` | Add spectrum canvas, drawSpectrumBars() JS, frequency readout |
| `platformio.ini` | Add `kosme/arduinoFFT@^2.0` to lib_deps |

### Unit Tests — `test/test_fft/test_fft_analysis.cpp` (NEW)
Uses `arduinoFFT` library directly on native platform (pure C++, no hardware dependency).

| # | Test Name | What It Verifies |
|---|-----------|-----------------|
| 1 | `test_fft_silence` | Zero-input → all bins near zero, no dominant frequency |
| 2 | `test_fft_440hz_sine` | 440Hz sine wave → dominant frequency ≈ 440 Hz (within 1 bin width) |
| 3 | `test_fft_1khz_sine` | 1kHz sine wave → dominant frequency ≈ 1000 Hz |
| 4 | `test_fft_dominant_frequency_accuracy` | Known test tones at 100, 500, 2000, 10000 Hz → correct identification |
| 5 | `test_spectrum_band_aggregation_48k` | At 48kHz: FFT bins correctly aggregate into 16 bands |
| 6 | `test_spectrum_band_aggregation_44k` | At 44.1kHz: same bands, different bin mapping |
| 7 | `test_spectrum_band_aggregation_16k` | At 16kHz: bands above 8kHz are zero (beyond Nyquist) |
| 8 | `test_spectrum_single_tone_in_correct_band` | 250Hz tone → energy only in Band 3 (250-500Hz) |
| 9 | `test_spectrum_normalization` | Band values are 0.0-1.0 normalized |
| 10 | `test_fft_window_applied` | Hamming window reduces spectral leakage vs rectangular window |

---

## Frontend Design: Dedicated "Audio" Tab

### Tab Bar Change
Insert **Audio** tab after Control, before WiFi. Tab order becomes:
```
Control | Audio | WiFi | MQTT | Settings | Support | Debug
```
- Tab icon/label: "Audio" (or speaker icon on mobile)
- Desktop sidebar: New nav item between Control and WiFi
- `switchTab('audio')` triggers waveform subscription (starts streaming)
- Leaving Audio tab sends unsubscribe (stops streaming, saves bandwidth)

### Audio Tab Layout (~600px total height, 4 cards)

```
┌─────────────────────────────────────┐
│ ■ Audio Waveform                    │  Card 1
│ ┌─────────────────────────────────┐ │
│ │░░░░░▓▓▓▓█████▓▓▓░░░░░░▓▓████░░│ │  Canvas 140px
│ │░░▓▓██████████████▓▓░▓▓███████▓░│ │  Orange waveform on dark bg
│ │────────── center line ──────────│ │  Center line = silence
│ │░░▓▓██████████████▓▓░▓▓███████▓░│ │
│ │░░░░░▓▓▓▓█████▓▓▓░░░░░░▓▓████░░│ │
│ └─────────────────────────────────┘ │
└─────────────────────────────────────┘

┌─────────────────────────────────────┐
│ ■ Frequency Spectrum                │  Card 2
│  Dominant: 440 Hz                   │  Frequency readout
│ ┌─────────────────────────────────┐ │
│ │  █                              │ │  Canvas 120px
│ │  █ █                            │ │  16 vertical bars
│ │█ █ █ █                          │ │  Orange-to-red gradient
│ │█ █ █ █ █ █                      │ │  Band labels below
│ │█ █ █ █ █ █ █ █ █               │ │
│ │Sub Bass Mid  Hi  Air            │ │
│ └─────────────────────────────────┘ │
└─────────────────────────────────────┘

┌─────────────────────────────────────┐
│ ■ Audio Levels                      │  Card 3
│                                     │
│  L ████████████████░░░░░░|░░  -12  │  Left channel bar + peak hold + dBFS
│  R ██████████████░░░░░░░░|░░  -15  │  Right channel bar + peak hold + dBFS
│                                     │
│  Level    -13.5 dBFS               │  Combined level readout
│  Signal   ● Detected               │  Green dot = detected, gray = not
│  Balance  ◄══════●══════►  0%      │  Center-weighted balance indicator
└─────────────────────────────────────┘

┌─────────────────────────────────────┐
│ ■ Audio Settings                    │  Card 4
│                                     │
│  Sample Rate        [48000 Hz ▾]   │  Dropdown: 16000/44100/48000
│  Detection Threshold [-40 dBFS]    │  Input: -96 to 0
│  Viz Refresh Rate    [100ms   ▾]   │  Dropdown: 50/100/200/500ms
└─────────────────────────────────────┘
```

### CSS Patterns (reuse existing)
- Cards: `.card` class (12px border-radius, surface background, 16px padding)
- Canvases: `.graph-embedded` (dark #1A1A1A bg, 12px padding)
- Level bars: Custom CSS with gradient fill (`linear-gradient(to right, #4CAF50, #FFC107, #FF9800, #F44336)`)
- Peak hold: Absolute-positioned 2px marker on the bar
- Balance indicator: Range slider styled as center-weighted bar
- Info rows: `.info-row` with `.info-label` + `.info-value`
- Dropdowns/inputs: Existing form styling (`.form-group select`, `.form-group input`)

### Color Scheme (matching orange accent theme)
- Waveform line: `#FF9800` (orange accent)
- Spectrum bars: Gradient `#FF9800` → `#F44336` (orange → red) based on intensity
- Level bar fill: `#4CAF50` → `#FFC107` → `#FF9800` → `#F44336` (green → yellow → orange → red)
- Peak hold marker: `#FFFFFF` (white, 2px width)
- Signal detected dot: `#4CAF50` (green) / `#666` (gray)
- Canvas background: `#1A1A1A` (matches existing debug graphs)
- Grid lines: `#333` (matches existing debug graphs)

### JavaScript Functions (in `web_pages.cpp`)
```
drawAudioWaveform(data)     — Renders 256-point waveform on canvas
drawSpectrumBars(bands)     — Renders 16-band frequency bars on canvas
updateLevelMeters(rmsL, rmsR, peakL, peakR, dBFS) — Updates CSS bar widths + text
updateFrequencyDisplay(freq) — Updates "Dominant: 440 Hz" text
```

### WebSocket Integration
- On entering Audio tab: `ws.send(JSON.stringify({type:'subscribeAudio', enabled:true}))`
- On leaving Audio tab: `ws.send(JSON.stringify({type:'subscribeAudio', enabled:false}))`
- ESP32 tracks subscription per client, sends `audioWaveform` + `audioSpectrum` only to subscribers
- Level meter data comes via existing `smartSensing` message (always broadcast, 1s rate)
- Waveform + spectrum sent at configurable rate (default 100ms = 10Hz) only to subscribers

### Responsive Behavior
- **Mobile (≤480px):** Full-width cards, canvases scale to container width, level bars stack
- **Tablet (768px+):** Cards have more padding, canvases get more horizontal detail
- **Desktop (1024px+):** Waveform and spectrum canvases side-by-side (2-column grid) if screen allows, otherwise stacked
- **All sizes:** Level meters always full-width horizontal bars

### Files Modified for Frontend
| File | Change |
|------|--------|
| `src/web_pages.cpp` | Add Audio tab HTML (nav button + panel div), 4 cards, CSS for level bars/spectrum, JS draw functions, subscription logic |
| `src/web_pages_gz.cpp` | Regenerated from web_pages.cpp after changes (via build_web_assets.js) |
| `src/websocket_handler.cpp` | Add `subscribeAudio` message handler, per-client subscription tracking, selective send for `audioWaveform` + `audioSpectrum` messages |

---

## Deferred Phases (Future)

### Phase 5: Advanced DSP — Noise gate with hysteresis, stereo correlation, audio source classification
### Phase 6: LVGL GUI Audio Screen — Level bars, frequency, mini spectrum on TFT display
### Phase 7: MQTT Audio Entities — Dedicated audio topics for Home Assistant integration

These can be planned in detail after Phases 1-4 are tested on hardware.

---

## Resource Impact (Phases 1-4)

| Phase | Flash | RAM | CPU |
|-------|-------|-----|-----|
| 1: Core I2S + dBFS | +15 KB | +10 KB (DMA) | ~2% |
| 2: Level Metering | +8 KB (CSS/JS) | <1 KB | <1% |
| 3: Waveform Viz | +10 KB (JS) | +1 KB (buffer) | ~1% |
| 4: FFT/Spectrum | +20 KB (lib) | +16 KB (FFT buffers) | ~3% |
| **Total** | **~53 KB** | **~28 KB** | **~7%** |

Current headroom: 1.4 MB flash, 221 KB RAM. Phases 1-4 use ~4% flash, ~13% of free RAM.

---

## Implementation Order

1. **Phase 1** first — get I2S working and verify on hardware
2. **Phase 2** can be partially done within Phase 1 (level metering comes naturally from RMS computation)
3. **Phase 3** after Phase 1 hardware validation — waveform visualization
4. **Phase 4** last — FFT adds the `arduinoFFT` library dependency

Each phase builds on the previous and can be tested independently.

---

## Test Summary

| Phase | Test File | New Tests | Total |
|-------|-----------|-----------|-------|
| 1 | `test/test_i2s_audio/test_audio_rms.cpp` (NEW) | 14 | 14 |
| 1 | `test/test_smart_sensing/` (MODIFIED) | 2 updated, ~8 unchanged | 10 |
| 2 | `test/test_i2s_audio/` (extended) | 5 | 19 |
| 3 | `test/test_i2s_audio/` (extended) | 5 | 24 |
| 3 | `test/test_websocket/` (extended) | 3 | 18 |
| 4 | `test/test_fft/test_fft_analysis.cpp` (NEW) | 10 | 10 |
| **Total new tests across all phases** | | **~39** | |

Current test count: 237. After all 4 phases: **~276 tests**.

---

## Verification Plan

### Phase 1
1. `pio test -e native` — 237 existing + 14 new audio RMS tests + updated smart sensing tests all pass
2. `pio run -e esp32-s3-devkitm-1` — firmware compiles
3. Hardware test:
   - Silence → dBFS reads ~-96, signal not detected, amplifier OFF
   - Play music → dBFS rises above -40 threshold, amplifier ON
   - Stop music → timer counts down, amplifier OFF
   - Web UI shows dBFS level and threshold correctly
   - MQTT publishes dBFS values
   - GUI home/control screens show dBFS
   - Old settings file auto-migrates voltage threshold to dBFS
   - Sample rate change (16k→48k) via API restarts I2S correctly

### Phase 2
1. `pio test -e native` — 5 new VU/peak tests pass
2. Hardware: Level bars animate smoothly with VU ballistics, peak hold markers appear and decay

### Phase 3
1. `pio test -e native` — 5 new waveform + 3 subscription tests pass
2. Hardware: Waveform canvas shows recognizable audio shape
3. Updates stop when leaving Control tab (subscription protocol works)
4. No impact on WebSocket performance for other message types

### Phase 4
1. `pio test -e native` — 10 new FFT tests pass (arduinoFFT runs on native platform)
2. Hardware: Frequency readout shows reasonable values for known test tones
3. Spectrum bars respond to different audio content (bass-heavy vs treble-heavy)
4. FFT computation doesn't impact I2S capture (no dropped samples)
5. Band mapping adapts correctly when sample rate is changed
